---
title: "Functional Programming for Data Science"
date: "2017-03-03T21:48:51-07:00"
---


<!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE -->

<p>A common problem in professional data science roles is the frictioin between developing an analysis and deploying it. An analyst might spend a lot of time generating an excellent prediction algorithm only to abandon it when it’s difficult to implement. Currently there’s a lot of work going on trying to close this gap through tools like <a href="https://www.tensorflow.org/">TensorFlow</a> or <a href="https://www.rstudio.com/products/connect/">RStudio Connect</a> but there are a few general things that analysts can do to make sure that their analyses can be deployed without headache. One of those things is to adopt a functional programming paradigm.</p>
<div id="the-gap-between-development-and-deployment" class="section level3">
<h3>The gap between development and deployment</h3>
<p>I think problems deploying data science solutions are caused by three main characteristics of data science work:</p>
<div id="data-science-problems-are-vague-in-conception-but-precise-in-application" class="section level4">
<h4>1) Data science problems are vague in conception but precise in application</h4>
<p>Relative to most engineering problems, data science work is exploratory. For instance a front-end engineer usually starts work with a fairly clear idea of what they are going to build. They may get a set of wireframes, or a requirements document, but at the very least they know how their work is going to be deployed.</p>
<p>Analysis problems by contrast usually start with a question like “why did our traffic fall last month”. The answers to these questions are usually what drives whether and how that analysis will be deployed. Maybe you start producing a monthly report about a new traffic metric, maybe you set up a daily traffic warning system, or maybe you deploy a predictive algorithm to estimate traffic going forward. Because you don’t know what the answer is going to be it’s hard to develop the analysis in a way which handles each deployment case.</p>
</div>
<div id="analyses-are-developed-on-small-datasets-but-applied-to-large-datasets" class="section level4">
<h4>2) Analyses are developed on small datasets but applied to large datasets</h4>
<p>Working on large datasets is annoying and slow, so most analysts try to shrink the dataset down in order to be able to iterate quickly. This might mean working on a single month of data, or sampling it in some way, or just taking a snapshot of data which is constantly being updated. This means you can develop a solution quickly without having to worry about moving data between different machines.</p>
<p>The problem comes when you then go to deploy that analysis on a server or on a cluster of servers. The code you wrote which worked fine locally might not be built in a way which can be distributed, and as a result the project might need a lot of refactoring before it can be deployed.</p>
</div>
<div id="analysts-are-not-trained-to-deploy-things" class="section level4">
<h4>3) Analysts are not trained to deploy things</h4>
<p>Data scientists often come from formal statistics backgrounds or from business intelligence roles, neither of which are typically concerned with deploying solutions. As a statisticisan you might be worried about getting your work to function on a single dataset for a particular paper, and as a BI person you are probably able to babysit your analysis to fix problems as they arise. Things like unit tests, continuous integration, version control, and dependency management are not typically problems which come up in these domains and so people who work in these domains don’t know how to guard against them.</p>
</div>
</div>
<div id="what-is-functional-programming" class="section level3">
<h3>What is Functional Programming</h3>
<p>Functional programming is a paraidgm where you</p>
</div>


<!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD -->
